---
title:  'GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting'  #  Paper title, covered by ''
teser: 2024gala3d.png
type:   paper
pro_type: 3D Generation
layout: post  #  Do not change this
date:   2024-03-01 11:59:59 +0800  # paper pub data, only change year and month according to this format
author: Xiaoyu Zhou, Xingjian Ran, Yajiao Xiong, Jinlin He, Zhiwei Lin, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang # authors information
venue:  ICML 2024
year:   2024  # paper year, number
month:  March # paper month, full name
projectPage: None  # If has project page, link here, otherwise None
supplemental: https://arxiv.org/abs/2402.07207
data: None  # If has data, post data link here, otherwise None
code: https://github.com/VDIGPKU/GALA3D  # If has data, post code link here, otherwise None
paperLink: https://arxiv.org/abs/2402.07207 # post paper pdf link here
---

We present GALA3D, generative 3D GAussians with LAyout-guided control, for effective compositional text-to-3D generation. We first utilize large language models (LLMs) to generate the initial layout and introduce a layout-guided 3D Gaussian representation for 3D content generation with adaptive geometric constraints. We then propose an instance-scene compositional optimization mechanism with conditioned diffusion to collaboratively generate realistic 3D scenes with consistent geometry, texture, scale, and accurate interactions among multiple objects while simultaneously adjusting the coarse layout priors extracted from the LLMs to align with the generated scene. Experiments show that GALA3D is a user-friendly, end-to-end framework for state-of-the-art scene-level 3D content generation and controllable editing while ensuring the high fidelity of object-level entities within the scene. The source codes and models will be available at gala3d.github.io.
